{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_svg_display():\n",
    "    \"\"\"Use the svg format to display plot in jupyter.\"\"\"\n",
    "    display.set_matplotlib_formats('svg')\n",
    "\n",
    "def set_figsize(figsize=(3.5, 2.5)):\n",
    "    \"\"\"Change the default figure size\"\"\"\n",
    "    use_svg_display()\n",
    "    plt.rcParams['figure.figsize'] = figsize\n",
    "    \n",
    "def show_trace_2d(f, results):\n",
    "    \"\"\"Show the trace of 2D variables during optimization.\"\"\"\n",
    "    set_figsize((3.5, 2.5))\n",
    "    plt.plot(*zip(*results), '-o', color='#ff7f0e')\n",
    "    x1, x2 = np.meshgrid(np.arange(-5.5, 1.0, 0.1), np.arange(-3.0, 1.0, 0.1))\n",
    "    plt.contour(x1, x2, f(x1, x2), colors='#1f77b4')\n",
    "    plt.xlabel('x1')\n",
    "    plt.ylabel('x2')\n",
    "    \n",
    "def train_2d(trainer):\n",
    "    \"\"\"Optimize a 2-dim objective function with a customized trainer.\"\"\"\n",
    "    # s1 and s2 are internal state variables and will \n",
    "    # be used later in the chapter\n",
    "    x, s1, s2 =tf.constant([-5.0, -2.0],shape=(1,2)) , tf.constant([0.0,0.0],shape=(1,2)),tf.constant([0.0,0.0],shape=(1,2))\n",
    "    results = [x.numpy()]\n",
    "    for i in range(20):\n",
    "        x, s1, s2 = trainer(x, s1, s2)\n",
    "        results.append(x.numpy())\n",
    "    print('epoch :',i + 1,'  x: ', x.numpy())\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 介绍\n",
    "AdaDelta 也是解决在adagrad算法中在后期学习率变小不能找到合适解的问题，有趣的是在AdaDetla中没有学习率这个超参数.\n",
    "AdaDelta算法也像RMSProp算法一样，使用了小批量随机梯度$g_t$按元素平方的指数加权移动平均变量$s_t$。在时间步0，它的所有元素被初始化为0。给定超参数$0 \\leq \\rho < 1$ （对应RMSProp算法中的 γ ），在时间步 t>0 ，同RMSProp算法一样计算\n",
    "$$\\boldsymbol{s}_t \\leftarrow \\rho \\boldsymbol{s}_{t-1} + (1 - \\rho) \\boldsymbol{g}_t \\odot \\boldsymbol{g}_t.$$\n",
    "\n",
    "与RMSProp算法不同的是，AdaDelta算法还维护一个额外的状态变量$\\Delta\\boldsymbol{x}_t$ ，其元素同样在时间步0时被初始化为0。我们使用 $\\Delta\\boldsymbol{x}_{t-1}$ 来计算自变量的变化量\n",
    "$$\\boldsymbol{g}_t' \\leftarrow \\sqrt{\\frac{\\Delta\\boldsymbol{x}_{t-1} + \\epsilon}{\\boldsymbol{s}_t + \\epsilon}}   \\odot \\boldsymbol{g}_t,$$\n",
    "接着更新自变量:\n",
    "$$\\boldsymbol{x}_t \\leftarrow \\boldsymbol{x}_{t-1} - \\boldsymbol{g}'_t.$$\n",
    "最后，我们使用$\\Delta\\boldsymbol{x}_t$ 来记录自变量变化量$\\boldsymbol{g}'_t$按元素平方的指数加权移动平均：\n",
    "$$\\Delta\\boldsymbol{x}_t \\leftarrow \\rho \\Delta\\boldsymbol{x}_{t-1} + (1 - \\rho) \\boldsymbol{g}'_t \\odot \\boldsymbol{g}'_t.$$\n",
    "\n",
    "可以看到，如不考虑 ϵ 的影响，AdaDelta算法与RMSProp算法的不同之处在于使用$\\sqrt{\\Delta\\boldsymbol{x}_{t-1}}$来替代超参数 η "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fx(x):\n",
    "    w = tf.constant([4,-3],dtype=tf.float32)\n",
    "    \n",
    "    return tf.reduce_sum(x*w,axis=1)+5.0 + tf.random.normal(shape=(x.shape[0],))\n",
    "\n",
    "x = tf.random.normal(shape=(1000,2))\n",
    "y = fx(x)\n",
    "\n",
    "def create_ds(x,y,batch_size):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((x,y))\n",
    "    return ds.shuffle(1000).batch(batch_size).repeat()\n",
    "\n",
    "ds = create_ds(x,y,20)\n",
    "\n",
    "temp_x,temp_y = next(iter(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(MyLayer,self).__init__(**kwargs)\n",
    "        self.w = self.add_weight(name=\"w\",shape=(1,2),trainable = True,dtype=tf.float32,initializer=tf.keras.initializers.he_normal())\n",
    "        self.b = self.add_weight(name=\"b\",shape=(1,),trainable = True,dtype=tf.float32,initializer=tf.keras.initializers.he_normal())\n",
    "    \n",
    "    def call(self,x):\n",
    "        return tf.reduce_sum(x * self.w,axis=1,name=\"sum\") + self.b\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    MyLayer()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 100 steps\n",
      "Epoch 1/20\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.0263 - mae: 0.8140\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 0s 922us/step - loss: 1.0262 - mae: 0.8139\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 0s 882us/step - loss: 1.0262 - mae: 0.8139\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 0s 922us/step - loss: 1.0262 - mae: 0.8139\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 0s 862us/step - loss: 1.0261 - mae: 0.8139\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 0s 852us/step - loss: 1.0261 - mae: 0.8139\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 0s 862us/step - loss: 1.0261 - mae: 0.8139\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 0s 892us/step - loss: 1.0260 - mae: 0.8138\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 0s 832us/step - loss: 1.0261 - mae: 0.8139\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 0s 822us/step - loss: 1.0261 - mae: 0.8140\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 0s 822us/step - loss: 1.0261 - mae: 0.8140\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 0s 822us/step - loss: 1.0261 - mae: 0.8138\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 0s 822us/step - loss: 1.0261 - mae: 0.8140\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 0s 832us/step - loss: 1.0261 - mae: 0.8139\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 0s 822us/step - loss: 1.0260 - mae: 0.8138\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 0s 832us/step - loss: 1.0261 - mae: 0.8138\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 0s 892us/step - loss: 1.0261 - mae: 0.8139\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 0s 822us/step - loss: 1.0260 - mae: 0.8139\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 0s 822us/step - loss: 1.0261 - mae: 0.8137\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 0s 922us/step - loss: 1.0261 - mae: 0.8138\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=tf.losses.mean_squared_error,metrics=[\"mae\"],optimizer=tf.keras.optimizers.Adadelta(rho=0.95,learning_rate=1))\n",
    "history = model.fit(ds,epochs=20,steps_per_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'w:0' shape=(1, 2) dtype=float32, numpy=array([[ 3.9851315, -3.0006926]], dtype=float32)>,\n",
       " <tf.Variable 'b:0' shape=(1,) dtype=float32, numpy=array([5.002375], dtype=float32)>]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2.0",
   "language": "python",
   "name": "tensorflow2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
