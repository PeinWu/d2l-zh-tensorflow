{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers\n",
    "import numpy as np\n",
    "import pathlib\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 稠密网络\n",
    "DenseNet是对残差网络的改进，主要的区别是在最后使用相连个不是相加\n",
    "\n",
    "![Image text](http://zh.d2l.ai/_images/densenet.svg)\n",
    "\n",
    "    ResNet（左）与DenseNet（右）在跨层连接上的主要区别：使用相加和使用连结\n",
    "    \n",
    "DenseNet的主要构建模块是稠密块（dense block）和过渡层（transition layer）。前者定义了输入和输出是如何连结的，后者则用来控制通道数，使之不过大。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 稠密块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(num_chanel):\n",
    "    '''卷积块 使用归一化-》激活-》卷积的结构'''\n",
    "    net = keras.Sequential([\n",
    "        \n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation(\"relu\"),\n",
    "        layers.Conv2D(num_chanel,kernel_size=3,padding=\"SAME\")\n",
    "    ])\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseBlock(layers.Layer):\n",
    "    def __init__(self,num_convs,num_chanel,**kwargs):\n",
    "        super(DenseBlock,self).__init__(**kwargs)\n",
    "        self.nets = []\n",
    "        for i in range(num_convs):\n",
    "            self.nets.append(conv_block(num_chanel))\n",
    "    def call(self,x):\n",
    "        for block in self.nets:\n",
    "            Y = block(x)\n",
    "            x = layers.concatenate([x,Y],axis=-1)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=498, shape=(1, 4, 4, 7), dtype=float32, numpy=\n",
       "array([[[[-1.0368147 ,  0.6697251 ,  1.6194909 ,  0.20595467,\n",
       "           0.75002205, -0.26975372,  0.6110288 ],\n",
       "         [-1.2829692 , -1.4954864 , -1.3055717 , -0.05915384,\n",
       "          -0.14918953,  0.36398026, -0.61129034],\n",
       "         [-0.9239982 ,  1.1946514 , -0.85230935,  0.20345391,\n",
       "           0.4246419 , -0.62845856, -0.61903536],\n",
       "         [-1.6430733 ,  0.37067288,  1.2175114 ,  1.0778502 ,\n",
       "           0.26581043, -0.25803944,  0.12376683]],\n",
       "\n",
       "        [[-1.5444536 , -0.8612828 , -1.1591899 , -0.74813616,\n",
       "          -0.07419045, -0.39979878, -1.2058747 ],\n",
       "         [ 1.5539789 , -0.09261205, -1.4822873 , -0.62113094,\n",
       "           0.08281277,  0.0432386 , -0.09155516],\n",
       "         [ 1.0333538 ,  0.02673283, -0.31871417, -0.80178916,\n",
       "          -0.18240494,  0.33101416, -0.57941014],\n",
       "         [ 0.6644254 , -1.288338  , -1.3305748 , -0.45774728,\n",
       "           0.12782294,  0.71323144, -0.5694542 ]],\n",
       "\n",
       "        [[ 0.7947546 , -0.19459051, -0.9084884 , -0.21597892,\n",
       "          -0.4189009 ,  0.22307613,  0.1468203 ],\n",
       "         [-0.5662626 , -0.17205848, -1.2265552 ,  0.30466834,\n",
       "          -0.30641556,  0.67049956,  0.05780889],\n",
       "         [-1.2963362 , -0.10481329, -1.5000234 , -0.42561185,\n",
       "          -0.16208223,  0.07594685,  0.05529606],\n",
       "         [ 0.15928234, -1.4907368 , -0.35540685, -0.04348067,\n",
       "          -0.03533874, -0.01090941,  0.06675752]],\n",
       "\n",
       "        [[ 0.33994755, -0.85289603, -0.8555669 , -0.4534938 ,\n",
       "           0.05342282, -0.1956091 ,  0.01105347],\n",
       "         [ 0.7715788 ,  0.9061937 , -0.47394055, -0.2171835 ,\n",
       "           0.27669296, -0.0437724 ,  0.08706906],\n",
       "         [-1.410981  , -0.02237408, -0.8152141 ,  0.12852596,\n",
       "           0.02406985,  0.41931245, -0.02160596],\n",
       "         [-0.09603174,  0.36909106, -0.523074  , -0.09829296,\n",
       "           0.09172595, -0.02022943,  0.07305112]]]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbk = DenseBlock(2,2)\n",
    "x = tf.random.normal(shape=(1,4,4,3))\n",
    "dbk(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 过渡层\n",
    "由于每个稠密块都会带来通道数的增加，使用过多则会带来过于复杂的模型。过渡层用来控制模型复杂度。它通过 1×1 卷积层来减小通道数，并使用步幅为2的平均池化层减半高和宽，从而进一步降低模型复杂度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition_block(num_chanel):\n",
    "    net = keras.Sequential(\n",
    "        [\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation(\"relu\"),\n",
    "            layers.Conv2D(num_chanel,kernel_size=1),\n",
    "            layers.AveragePooling2D(pool_size=(2,2),strides = 2)\n",
    "        ]\n",
    "    )\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=619, shape=(1, 2, 2, 10), dtype=float32, numpy=\n",
       "array([[[[-0.0126456 ,  0.08713236, -0.02637652,  0.20909722,\n",
       "          -0.11200319,  0.49369764,  0.09739993,  0.18114191,\n",
       "           0.12171778,  0.40193224],\n",
       "         [-0.2149685 , -0.00675567, -0.23784779,  0.23309761,\n",
       "           0.06407173,  0.3626266 , -0.08743507,  0.154962  ,\n",
       "           0.1982415 ,  0.60913813]],\n",
       "\n",
       "        [[ 0.0762403 , -0.18736482, -0.36718363,  0.17342336,\n",
       "          -0.03194648,  0.30088085, -0.03317501,  0.05320933,\n",
       "           0.27683806,  0.36614457],\n",
       "         [-0.00628484,  0.0262167 , -0.11096232,  0.02519948,\n",
       "          -0.01937193,  0.05943681, -0.00436193,  0.07345705,\n",
       "           0.09532285,  0.07405222]]]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tbk = transition_block(10)\n",
    "out1 = dbk(x)\n",
    "tbk(out1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DenseNet 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = keras.Sequential(\n",
    "    [\n",
    "        layers.InputLayer(input_shape=(224,224,3)),\n",
    "        layers.Conv2D(64,kernel_size=7,strides=3,padding=\"same\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation(\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(3,3),strides=2,padding=\"same\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_channels, growth_rate = 64, 32  # num_channels为当前的通道数\n",
    "num_convs_in_dense_blocks = [4, 4, 4, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,num_convs in enumerate(num_convs_in_dense_blocks):\n",
    "    net.add(DenseBlock(num_convs,growth_rate))\n",
    "    num_channels += num_channels + growth_rate\n",
    "    \n",
    "    if i != len(num_convs_in_dense_blocks)-1:\n",
    "        num_channels = num_channels // 2\n",
    "        net.add(transition_block(num_channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.add(layers.BatchNormalization())\n",
    "net.add(layers.Activation(\"relu\"))\n",
    "net.add(layers.GlobalAveragePooling2D())\n",
    "net.add(layers.Dense(5,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 75, 75, 64)        9472      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 75, 75, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 38, 38, 64)        0         \n",
      "_________________________________________________________________\n",
      "dense_block_4 (DenseBlock)   (None, 38, 38, 192)       130944    \n",
      "_________________________________________________________________\n",
      "sequential_12 (Sequential)   (None, 19, 19, 80)        16208     \n",
      "_________________________________________________________________\n",
      "dense_block_5 (DenseBlock)   (None, 19, 19, 208)       149632    \n",
      "_________________________________________________________________\n",
      "sequential_17 (Sequential)   (None, 9, 9, 96)          20896     \n",
      "_________________________________________________________________\n",
      "dense_block_6 (DenseBlock)   (None, 9, 9, 224)         168320    \n",
      "_________________________________________________________________\n",
      "sequential_22 (Sequential)   (None, 4, 4, 112)         26096     \n",
      "_________________________________________________________________\n",
      "dense_block_7 (DenseBlock)   (None, 4, 4, 240)         187008    \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 4, 4, 240)         960       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 4, 4, 240)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 240)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 1205      \n",
      "=================================================================\n",
      "Total params: 710,997\n",
      "Trainable params: 704,789\n",
      "Non-trainable params: 6,208\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=3963, shape=(1, 5), dtype=float32, numpy=\n",
       "array([[0.19121608, 0.17145461, 0.16664892, 0.18089601, 0.28978434]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.normal(shape=(1,224,224,3))\n",
    "net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.compile(loss=keras.losses.sparse_categorical_crossentropy,metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = 224\n",
    "IMG_HEIGHT = 224\n",
    "BATCH_SIZE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"y:0\", shape=(5,), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "DATA_URL = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
    "data_dir = tf.keras.utils.get_file(fname=\"flower_photos\",origin=DATA_URL,untar=True)\n",
    "import pathlib\n",
    "data_dir = pathlib.Path(data_dir)\n",
    "ds = tf.data.Dataset.list_files(str(data_dir/'*/*'))\n",
    "class_lable =  np.array([ item.name for item in data_dir.glob(\"*\") if item.name != \"LICENSE.txt\" ])\n",
    "## 转换lable为数值型数据\n",
    "lable_dic =dict( zip(class_lable,np.asarray(range(0,len(class_lable)))))\n",
    "@tf.function\n",
    "def get_lable(x):\n",
    "    arr_str = tf.strings.split(x,sep=\"\\\\\")\n",
    "    return arr_str[-2] == class_lable\n",
    "\n",
    "def decode_img(img):\n",
    "    img = tf.image.decode_image(img,channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    img = tf.image.resize_with_crop_or_pad(img,IMG_WIDTH,IMG_HEIGHT)\n",
    "    img = tf.image.random_flip_left_right(img)\n",
    "    img = tf.image.random_flip_up_down(img)\n",
    "    return img\n",
    "\n",
    "def img_map_fun(x):\n",
    "    lable = get_lable(x)\n",
    "    img = tf.io.read_file(x)\n",
    "    img = decode_img(img)\n",
    "    return img,lable\n",
    "\n",
    "lable = tf.constant([0,1,2,3,4])\n",
    "@tf.function\n",
    "def map_lable_fun(x,y):\n",
    "    print(y)\n",
    "    y = lable[y][0]\n",
    "    return x,y\n",
    "\n",
    "ds = ds.map(map_func=img_map_fun,num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds = ds.map(map_func=map_lable_fun)\n",
    "\n",
    "def prepare_for_training(ds, cache=True, shuffle_buffer_size=1000,batch_size = 256):\n",
    "    # This is a small dataset, only load it once, and keep it in memory.\n",
    "    # use `.cache(filename)` to cache preprocessing work for datasets that don't\n",
    "    # fit in memory.\n",
    "    if cache:\n",
    "        if isinstance(cache, str):\n",
    "            ds = ds.cache(cache)\n",
    "    else:\n",
    "        ds = ds.cache()\n",
    "\n",
    "    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
    "\n",
    "    # Repeat forever\n",
    "    ds = ds.repeat()\n",
    "\n",
    "    ds = ds.batch(batch_size)\n",
    "\n",
    "    # `prefetch` lets the dataset fetch batches in the background while the model\n",
    "    # is training.\n",
    "    ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return ds\n",
    "\n",
    "ds = prepare_for_training(ds,batch_size = BATCH_SIZE)\n",
    "\n",
    "image_batch, label_batch = next(iter(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=4981, shape=(5, 5), dtype=float32, numpy=\n",
       "array([[0.19351912, 0.1949397 , 0.19399604, 0.19807075, 0.21947442],\n",
       "       [0.19598795, 0.19492997, 0.19351491, 0.1984611 , 0.21710601],\n",
       "       [0.1974636 , 0.19695452, 0.1944998 , 0.19710729, 0.21397471],\n",
       "       [0.1953928 , 0.19627978, 0.19487058, 0.19970813, 0.21374863],\n",
       "       [0.19632544, 0.19590735, 0.1938132 , 0.19858308, 0.21537088]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(image_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 100 steps\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 70s 701ms/step - loss: 1.2935 - acc: 0.4600\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 68s 678ms/step - loss: 1.3254 - acc: 0.4620\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 67s 674ms/step - loss: 1.3471 - acc: 0.4160\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 67s 674ms/step - loss: 1.2814 - acc: 0.4600\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 68s 679ms/step - loss: 1.2745 - acc: 0.4660\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 67s 672ms/step - loss: 1.3460 - acc: 0.4620\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 66s 664ms/step - loss: 1.2660 - acc: 0.4620\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 69s 692ms/step - loss: 1.2113 - acc: 0.5440\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 70s 696ms/step - loss: 1.1773 - acc: 0.5260\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 68s 685ms/step - loss: 1.2816 - acc: 0.5020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x47ab02b0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fit(ds,steps_per_epoch=100,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.0",
   "language": "python",
   "name": "tensorflow2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
