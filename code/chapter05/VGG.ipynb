{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG块的组成规律是：连续使用数个相同的填充为1、窗口形状为 3×3 的卷积层后接上一个步幅为2、窗口形状为 2×2 的最大池化层。卷积层保持输入的高和宽不变，而池化层则对其减半。我们使用vgg_block函数来实现这个基础的VGG块，它可以指定卷积层的数量num_convs和输出通道数num_channels。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_block(num_convs,num_chanels):\n",
    "    block = tf.keras.Sequential()\n",
    "    \n",
    "    for i in range(num_convs):\n",
    "        block.add(tf.keras.layers.Conv2D(num_chanels,padding=\"SAME\",kernel_size=3,activation=\"relu\"))\n",
    "    \n",
    "    block.add(tf.keras.layers.MaxPooling2D(strides=(2,2)))\n",
    "    \n",
    "    return block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "block = vgg_block(3,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 10, 10, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.normal(shape=(10,10,3))\n",
    "x = tf.expand_dims(x,axis=0)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=117, shape=(1, 5, 5, 10), dtype=float32, numpy=\n",
       "array([[[[0.        , 0.10137452, 0.        , 0.14878502, 0.18936999,\n",
       "          0.02584816, 0.09371764, 0.186245  , 0.02967511, 0.04456124],\n",
       "         [0.        , 0.06417146, 0.        , 0.42978048, 0.30050197,\n",
       "          0.13600703, 0.26666224, 0.11881069, 0.        , 0.22648938],\n",
       "         [0.        , 0.03752999, 0.00922242, 0.5127882 , 0.32265666,\n",
       "          0.0049084 , 0.33574885, 0.31328893, 0.        , 0.26153153],\n",
       "         [0.        , 0.        , 0.        , 0.6435751 , 0.6219014 ,\n",
       "          0.2828443 , 0.40782544, 0.52491957, 0.        , 0.5629289 ],\n",
       "         [0.45518944, 0.1427342 , 0.27428615, 0.16438232, 0.5126835 ,\n",
       "          0.18664551, 0.49226454, 0.55698943, 0.23810351, 0.1609131 ]],\n",
       "\n",
       "        [[0.        , 0.0620217 , 0.        , 0.33673525, 0.24686882,\n",
       "          0.        , 0.3010417 , 0.18256554, 0.2220302 , 0.10178997],\n",
       "         [0.06329435, 0.19489193, 0.        , 0.5316355 , 0.03040163,\n",
       "          0.07715385, 0.3075515 , 0.13364199, 0.        , 0.10007888],\n",
       "         [0.22021219, 0.0974392 , 0.0280123 , 0.46114242, 0.10975367,\n",
       "          0.10265075, 0.42351222, 0.22163323, 0.03919233, 0.24791507],\n",
       "         [0.25251338, 0.18652123, 0.        , 0.7019162 , 0.8481153 ,\n",
       "          0.07579373, 0.89705694, 0.39150447, 0.        , 0.410632  ],\n",
       "         [0.4508109 , 0.0976645 , 0.14010262, 0.44810626, 0.34084228,\n",
       "          0.42383596, 0.8370161 , 0.45606613, 0.2875696 , 0.08931728]],\n",
       "\n",
       "        [[0.10861041, 0.18223748, 0.        , 0.34396443, 0.20629203,\n",
       "          0.12259378, 0.16006345, 0.33138654, 0.        , 0.35946393],\n",
       "         [0.        , 0.19393256, 0.        , 0.1895462 , 0.33465058,\n",
       "          0.10210717, 0.49858922, 0.17573333, 0.00900473, 0.43493026],\n",
       "         [0.1341522 , 0.13803713, 0.        , 0.16091184, 0.50091934,\n",
       "          0.        , 0.66439015, 0.31632414, 0.18662211, 0.2630153 ],\n",
       "         [0.27001518, 0.11484218, 0.23685905, 0.6676773 , 0.41712868,\n",
       "          0.11436448, 0.36549872, 0.3368131 , 0.        , 0.        ],\n",
       "         [0.2533476 , 0.03596693, 0.06982177, 0.44188926, 0.22129373,\n",
       "          0.22791423, 0.71799517, 0.45853567, 0.2613428 , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        , 0.3823395 , 0.26072273,\n",
       "          0.01309142, 0.23781353, 0.20848246, 0.        , 0.30757707],\n",
       "         [0.        , 0.        , 0.        , 0.40063387, 0.3418088 ,\n",
       "          0.0088258 , 0.40438735, 0.36374548, 0.11756974, 0.03075118],\n",
       "         [0.25326285, 0.17060155, 0.11531583, 0.5230955 , 0.06818014,\n",
       "          0.        , 0.31523746, 0.5476112 , 0.1434272 , 0.18709059],\n",
       "         [0.        , 0.13779987, 0.        , 0.04043699, 0.18011671,\n",
       "          0.26519525, 0.48649555, 0.1356965 , 0.        , 0.22209264],\n",
       "         [0.02433725, 0.        , 0.02614034, 0.01617356, 0.21458848,\n",
       "          0.08520544, 0.39233652, 0.26218998, 0.12400068, 0.02761789]],\n",
       "\n",
       "        [[0.14486717, 0.        , 0.12618177, 0.18044487, 0.21595058,\n",
       "          0.        , 0.40668947, 0.        , 0.        , 0.18120503],\n",
       "         [0.02410242, 0.06024893, 0.09947966, 0.2932288 , 0.02148787,\n",
       "          0.        , 0.65728045, 0.        , 0.03350844, 0.02504554],\n",
       "         [0.        , 0.        , 0.        , 0.3187416 , 0.3710536 ,\n",
       "          0.07259557, 0.43298867, 0.03925112, 0.        , 0.39337152],\n",
       "         [0.06069462, 0.        , 0.        , 0.39725155, 0.18428469,\n",
       "          0.08799052, 0.27630913, 0.05354062, 0.0164517 , 0.03882709],\n",
       "         [0.18630913, 0.05934979, 0.04440349, 0.12381628, 0.14283676,\n",
       "          0.02083001, 0.3685661 , 0.12881897, 0.        , 0.12248557]]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_arch = ((1, 64), (1, 128), (2, 256), (2, 512), (2, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(conv_arch,input_shape):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.InputLayer(input_shape= input_shape))\n",
    "    for num_conv,num_chanels in conv_arch:\n",
    "        model.add(vgg_block(num_conv,num_chanels))\n",
    "        \n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(4096,activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(4096,activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(10,activation=\"softmax\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(conv_arch,input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_8 (Sequential)    (None, 112, 112, 64)      1792      \n",
      "_________________________________________________________________\n",
      "sequential_9 (Sequential)    (None, 56, 56, 128)       73856     \n",
      "_________________________________________________________________\n",
      "sequential_10 (Sequential)   (None, 28, 28, 256)       885248    \n",
      "_________________________________________________________________\n",
      "sequential_11 (Sequential)   (None, 14, 14, 512)       3539968   \n",
      "_________________________________________________________________\n",
      "sequential_12 (Sequential)   (None, 7, 7, 512)         4719616   \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                40970     \n",
      "=================================================================\n",
      "Total params: 128,807,306\n",
      "Trainable params: 128,807,306\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 224, 224, 3])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.normal(shape=(224,224,3))\n",
    "x = tf.expand_dims(x,axis=0)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1017, shape=(1, 10), dtype=float32, numpy=\n",
       "array([[0.10672276, 0.09923742, 0.09782732, 0.09883187, 0.09900384,\n",
       "        0.09615097, 0.09905155, 0.10240912, 0.0993533 , 0.10141183]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = 224\n",
    "IMG_HEIGHT = 224\n",
    "BATCH_SIZE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"y:0\", shape=(5,), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "DATA_URL = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
    "data_dir = tf.keras.utils.get_file(fname=\"flower_photos\",origin=DATA_URL,untar=True)\n",
    "import pathlib\n",
    "data_dir = pathlib.Path(data_dir)\n",
    "ds = tf.data.Dataset.list_files(str(data_dir/'*/*'))\n",
    "class_lable =  np.array([ item.name for item in data_dir.glob(\"*\") if item.name != \"LICENSE.txt\" ])\n",
    "## 转换lable为数值型数据\n",
    "lable_dic =dict( zip(class_lable,np.asarray(range(0,len(class_lable)))))\n",
    "@tf.function\n",
    "def get_lable(x):\n",
    "    arr_str = tf.strings.split(x,sep=\"\\\\\")\n",
    "    return arr_str[-2] == class_lable\n",
    "\n",
    "def decode_img(img):\n",
    "    img = tf.image.decode_image(img,channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    img = tf.image.resize_with_crop_or_pad(img,IMG_WIDTH,IMG_HEIGHT)\n",
    "    img = tf.image.random_flip_left_right(img)\n",
    "    img = tf.image.random_flip_up_down(img)\n",
    "    return img\n",
    "\n",
    "def img_map_fun(x):\n",
    "    lable = get_lable(x)\n",
    "    img = tf.io.read_file(x)\n",
    "    img = decode_img(img)\n",
    "    return img,lable\n",
    "\n",
    "lable = tf.constant([0,1,2,3,4])\n",
    "@tf.function\n",
    "def map_lable_fun(x,y):\n",
    "    print(y)\n",
    "    y = lable[y][0]\n",
    "    return x,y\n",
    "\n",
    "ds = ds.map(map_func=img_map_fun,num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds = ds.map(map_func=map_lable_fun)\n",
    "\n",
    "def prepare_for_training(ds, cache=True, shuffle_buffer_size=1000,batch_size = 256):\n",
    "    # This is a small dataset, only load it once, and keep it in memory.\n",
    "    # use `.cache(filename)` to cache preprocessing work for datasets that don't\n",
    "    # fit in memory.\n",
    "    if cache:\n",
    "        if isinstance(cache, str):\n",
    "            ds = ds.cache(cache)\n",
    "    else:\n",
    "        ds = ds.cache()\n",
    "\n",
    "    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
    "\n",
    "    # Repeat forever\n",
    "    ds = ds.repeat()\n",
    "\n",
    "    ds = ds.batch(batch_size)\n",
    "\n",
    "    # `prefetch` lets the dataset fetch batches in the background while the model\n",
    "    # is training.\n",
    "    ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return ds\n",
    "\n",
    "ds = prepare_for_training(ds,batch_size = BATCH_SIZE)\n",
    "\n",
    "image_batch, label_batch = next(iter(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1589, shape=(5, 10), dtype=float32, numpy=\n",
       "array([[0.10124978, 0.09954045, 0.09985214, 0.09997739, 0.09965686,\n",
       "        0.09940214, 0.1002736 , 0.10035679, 0.09943722, 0.10025369],\n",
       "       [0.10150246, 0.09910905, 0.09979012, 0.09949955, 0.09971195,\n",
       "        0.09915818, 0.10021252, 0.1006892 , 0.09997004, 0.10035697],\n",
       "       [0.10143833, 0.09951892, 0.09982795, 0.10009196, 0.09982649,\n",
       "        0.09937846, 0.10010269, 0.10006729, 0.09961801, 0.10012981],\n",
       "       [0.10121918, 0.09976923, 0.09969419, 0.09999774, 0.09983264,\n",
       "        0.0993958 , 0.10007992, 0.10049582, 0.09968666, 0.09982888],\n",
       "       [0.10169157, 0.09927814, 0.09972777, 0.09979265, 0.09991218,\n",
       "        0.09926024, 0.10000106, 0.10059597, 0.09956744, 0.100173  ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(image_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 5 steps\n",
      "Epoch 1/2\n",
      "5/5 [==============================] - 52s 10s/step - loss: 11966.3771 - acc: 0.3200\n",
      "Epoch 2/2\n",
      "5/5 [==============================] - 40s 8s/step - loss: 8.9566 - acc: 0.2000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b8e11d0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(ds,steps_per_epoch=5,epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.0",
   "language": "python",
   "name": "tensorflow2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
